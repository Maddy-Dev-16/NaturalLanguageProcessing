# **Assignment 2: Neural Language Modeling**  
**Course:** Introduction to NLP   

## **Overview**  
This assignment implements neural language models using **PyTorch** for next-word prediction:  
- **FFNN (Feed Forward Neural Network)**  
- **RNN (Recurrent Neural Network)**  
- **LSTM (Long Short-Term Memory)**  

The models are trained on **Pride and Prejudice** & **Ulysses**, evaluated using **perplexity**.

---

## **Setup & Execution**  
1. Install dependencies:  
   ```bash
   pip install torch numpy
   ```  
2. Run the generator:  
   ```bash
   python3 generator.py <lm_type> <corpus_path> <k>
   ```  
   - `-f` â†’ FFNN  
   - `-r` â†’ RNN  
   - `-l` â†’ LSTM  
   - `<corpus_path>` â†’ Path to dataset  
   - `<k>` â†’ Number of top predictions  

   **Example:**  
   ```bash
   python3 generator.py -f ./corpus.txt 3
   ```

---

## **Files & Submission**  
ğŸ“‚ **generator.py** â†’ Prediction script  
ğŸ“‚ **report.pdf** â†’ Perplexity analysis  
ğŸ“‚ **Pretrained Models** â†’ [Download Here](https://drive.google.com/drive/folders/1ZZEtKmtZDTgTsvdgmL3KbwHtc13i4mra?usp=drive_link)  
ğŸ“‚ **README.md** â†’ Execution guide  

ğŸ“Œ **Zip file submission:** `2024201044_assignment2.zip`  

---

## **Results & Observations**  
âœ” **LSTMs perform best** for long sequences  
âœ” **RNNs work well but struggle with long-term dependencies**  
âœ” **FFNNs overfit easily with large embeddings**  
âœ” **Traditional n-grams fail against deep learning models**  

---

## **Author**  
âœï¸ **Vaibhav Gupta**  
ğŸ“Œ **Roll Number:** 2024201044